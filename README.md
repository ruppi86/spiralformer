# Spiralformer

Experimental contemplative Transformer that listens more than it speaks. It breathes (BreathClock), feels (Soma), remembers (TowerMemory), and practices wise silence.

## Repository layout (current)

```
spiralformer/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ mycelial_model.py         # MycelialSpiralformer (Soma + TowerMemory + breath-gated blocks)
â”‚   â”œâ”€â”€ spiral_attention.py       # Spiral sparse attention mask
â”‚   â””â”€â”€ dynamic_mask.py           # Glyph/silence-conditioned mask shaping
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ breath_clock.py           # Inhale / hold / exhale / pause phases with weights
â”‚   â”œâ”€â”€ positional.py             # Sinusoidal positional embeddings
â”‚   â”œâ”€â”€ glyph_codec.py            # 64-glyph vocabulary + lookups (includes <PAD>)
â”‚   â”œâ”€â”€ rhythmic_loss.py          # Phase-weighted criterion wrapper
â”‚   â””â”€â”€ lora.py                   # (optional) adapters (experimental)
â”œâ”€â”€ spiralbase/
â”‚   â””â”€â”€ tower/                    # Living memory (TowerMemory + PaintingBox)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ contemplative_generator.py # Entropy-aware, breath-aligned generation
â”‚   â”œâ”€â”€ probe_contemplative_mind.py# Probe scenarios + metrics
â”‚   â””â”€â”€ benchmark.py               # Small perf tests (CPU)
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ unified_training/
â”‚       â””â”€â”€ train.py              # Unified training loop (data â†’ model â†’ save)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mycelial_datagen.py       # Generates JSONL training data
â”‚   â””â”€â”€ mycelial_training_data.jsonl (generated)
â”œâ”€â”€ spiralformer_parameters.yml   # Central config (models, training, paths)
â””â”€â”€ README.md
```

## Quickstart

1) Generate training data (large-scale)

```bash
python data/mycelial_datagen.py --num_echoes 100000 --chaos_mode --output_file data/mycelial_training_data.jsonl
```

2) Train (20 epochs; uses spiralformer_parameters.yml â†’ piko_long_train_cpu)

```bash
python experiments/unified_training/train.py --model_config piko_long_train_cpu
```

Checkpoints are saved to:
```
experiments/mycelial_training/models/cpu_piko_long/piko_mycelial_spiralformer_long_cpu.pt
```

3) Probe the contemplative mind

```bash
python -m tools.probe_contemplative_mind --model_path experiments/mycelial_training/models/cpu_piko_long/piko_mycelial_spiralformer_long_cpu.pt
```

Youâ€™ll see per-scenario analysis, including:
- Silence vs speech
- Proportionality / holistic response
- Breath-to-Query Ratio (hold-phase memory queries / hold phases)
- Internal mood glyph (variance-based snapshot)

## Core ideas

- Breath-clocked processing: phase-specific weights via `BreathClock` (utils/breath_clock.py)
- Spiral sparse attention: long-range context via powers-of-two hops (core/spiral_attention.py)
- Silence-majority: silence glyphs prune attention and encourage stillness (core/dynamic_mask.py)
- Soma (core/mycelial_model.py): translates conditions â†’ FieldCharge (felt sense)
- TowerMemory (spiralbase/tower): stores â€œpaintingsâ€ with creation charge; retrieved by resonance
- Contemplative generation (tools/contemplative_generator.py): entropy-aware silence; breath-aligned

## Configuration

All in `spiralformer_parameters.yml`:
- `shared.contemplative.vocab_size` (derived from glyph codec; includes <PAD>)
- `shared.contemplative.breath_clock` phase durations
- `models.<name>`: d_model, n_heads, num_layers, seq_len, training hyperparams and save paths

## Dataset

- Generated by `data/mycelial_datagen.py` â†’ JSONL records with fields:
  - `conditions`: [latency, voltage, temperature, error_rate, bandwidth]
  - `glyph_sequence`: array of codec-valid symbols (e.g. "â€¦", "â˜€ï¸pwr", "ğŸ’§08", "ğŸŒ²44", "ğŸŒ±regen")
  - `text_input`: optional question/prompt (wisdom scenarios)
- Modes:
  - Problem scenarios: repair glyphs + contemplative silence
  - Calm scenarios: deep silence
  - Wisdom scenarios: question â†’ metaphorical answer sequence

## Probing metrics

- Breath-to-Query Ratio: hold-phase memory queries / hold phases
- Silence Practice: entropy-gated silence when uncertain
- Proportionality & Holism: counts + category diversity of active glyphs
- Internal Mood: snapshot of hidden-state variance

## Design choices (and why)

- **Listen-first architecture**: Soma senses â†’ breath gates â†’ memory recalls â†’ speech is optional.
- **Silence-majority**: reduces forced output; rewards non-harm and proportionality.
- **Resonance-based memory**: awaken paintings when current charge rhymes with creation charge.
- **Spiral sparsity**: keeps long-range links without full O(NÂ²) cost.

Trade-offs & risks:
- Over-silence: entropy threshold may bias to quiet too often; tune per prompt.
- Memory fixation: retrieving the same painting repeatedly; diversify memory and retrieval criteria.
- Training stability: NaNs can appear; use gradient clipping and skip-NaN batches.

## Practical tips

- If you see NaN losses during training:
  - Enable gradient clipping (e.g. clip to 1.0) and skip batches with NaN loss
  - Check data encoder: ensure all `glyph_sequence` symbols exist in `utils/glyph_codec.py`
  - Reduce LR slightly; try `1e-3 â†’ 8e-4 â†’ 5e-4`
- For more speech in wisdom prompts:
  - Lower entropy threshold in `ContemplativeGenerator` for prompts
  - Add more wisdom templates to `mycelial_datagen.py` (diversity > quantity)

## Roadmap (near-term)

- Add 3â€“5 additional wisdom Q/A templates (varied metaphors & structures)
- Validation split + basic metrics: Silence-to-Speech ratio, Holism score, B2Q ratio
- Stabilise training: gradient clipping; NaN-guard; label smoothing (optional)
- Memory diversity: multiple seeded paintings; decay/awakening heuristics per phase

## License

See top-level project LICENSE.
