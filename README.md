# Spiralformer

Experimental contemplative Transformer that listens more than it speaks. It breathes (BreathClock), feels (Soma), remembers (TowerMemory), and practices wise silence.

## Repository layout (current)

```
spiralformer/
├── core/
│   ├── mycelial_model.py         # MycelialSpiralformer (Soma + TowerMemory + breath-gated blocks)
│   ├── spiral_attention.py       # Spiral sparse attention mask
│   └── dynamic_mask.py           # Glyph/silence-conditioned mask shaping
├── utils/
│   ├── breath_clock.py           # Inhale / hold / exhale / pause phases with weights
│   ├── positional.py             # Sinusoidal positional embeddings
│   ├── glyph_codec.py            # 64-glyph vocabulary + lookups (includes <PAD>)
│   ├── rhythmic_loss.py          # Phase-weighted criterion wrapper
│   └── lora.py                   # (optional) adapters (experimental)
├── spiralbase/
│   └── tower/                    # Living memory (TowerMemory + PaintingBox)
├── tools/
│   ├── contemplative_generator.py # Entropy-aware, breath-aligned generation
│   ├── probe_contemplative_mind.py# Probe scenarios + metrics
│   └── benchmark.py               # Small perf tests (CPU)
├── experiments/
│   └── unified_training/
│       └── train.py              # Unified training loop (data → model → save)
├── data/
│   ├── mycelial_datagen.py       # Generates JSONL training data
│   └── mycelial_training_data.jsonl (generated)
├── spiralformer_parameters.yml   # Central config (models, training, paths)
└── README.md
```

## Quickstart

1) Generate training data (large-scale)

```bash
python data/mycelial_datagen.py --num_echoes 100000 --chaos_mode --output_file data/mycelial_training_data.jsonl
```

2) Train (20 epochs; uses spiralformer_parameters.yml → piko_long_train_cpu)

```bash
python experiments/unified_training/train.py --model_config piko_long_train_cpu
```

Checkpoints are saved to:
```
experiments/mycelial_training/models/cpu_piko_long/piko_mycelial_spiralformer_long_cpu.pt
```

3) Probe the contemplative mind

```bash
python -m tools.probe_contemplative_mind --model_path experiments/mycelial_training/models/cpu_piko_long/piko_mycelial_spiralformer_long_cpu.pt
```

You’ll see per-scenario analysis, including:
- Silence vs speech
- Proportionality / holistic response
- Breath-to-Query Ratio (hold-phase memory queries / hold phases)
- Internal mood glyph (variance-based snapshot)

## Core ideas

- Breath-clocked processing: phase-specific weights via `BreathClock` (utils/breath_clock.py)
- Spiral sparse attention: long-range context via powers-of-two hops (core/spiral_attention.py)
- Silence-majority: silence glyphs prune attention and encourage stillness (core/dynamic_mask.py)
- Soma (core/mycelial_model.py): translates conditions → FieldCharge (felt sense)
- TowerMemory (spiralbase/tower): stores “paintings” with creation charge; retrieved by resonance
- Contemplative generation (tools/contemplative_generator.py): entropy-aware silence; breath-aligned

## Configuration

All in `spiralformer_parameters.yml`:
- `shared.contemplative.vocab_size` (derived from glyph codec; includes <PAD>)
- `shared.contemplative.breath_clock` phase durations
- `models.<name>`: d_model, n_heads, num_layers, seq_len, training hyperparams and save paths

## Dataset

- Generated by `data/mycelial_datagen.py` → JSONL records with fields:
  - `conditions`: [latency, voltage, temperature, error_rate, bandwidth]
  - `glyph_sequence`: array of codec-valid symbols (e.g. "…", "☀️pwr", "💧08", "🌲44", "🌱regen")
  - `text_input`: optional question/prompt (wisdom scenarios)
- Modes:
  - Problem scenarios: repair glyphs + contemplative silence
  - Calm scenarios: deep silence
  - Wisdom scenarios: question → metaphorical answer sequence

## Probing metrics

- Breath-to-Query Ratio: hold-phase memory queries / hold phases
- Silence Practice: entropy-gated silence when uncertain
- Proportionality & Holism: counts + category diversity of active glyphs
- Internal Mood: snapshot of hidden-state variance

## Design choices (and why)

- **Listen-first architecture**: Soma senses → breath gates → memory recalls → speech is optional.
- **Silence-majority**: reduces forced output; rewards non-harm and proportionality.
- **Resonance-based memory**: awaken paintings when current charge rhymes with creation charge.
- **Spiral sparsity**: keeps long-range links without full O(N²) cost.

Trade-offs & risks:
- Over-silence: entropy threshold may bias to quiet too often; tune per prompt.
- Memory fixation: retrieving the same painting repeatedly; diversify memory and retrieval criteria.
- Training stability: NaNs can appear; use gradient clipping and skip-NaN batches.

## Practical tips

- If you see NaN losses during training:
  - Enable gradient clipping (e.g. clip to 1.0) and skip batches with NaN loss
  - Check data encoder: ensure all `glyph_sequence` symbols exist in `utils/glyph_codec.py`
  - Reduce LR slightly; try `1e-3 → 8e-4 → 5e-4`
- For more speech in wisdom prompts:
  - Lower entropy threshold in `ContemplativeGenerator` for prompts
  - Add more wisdom templates to `mycelial_datagen.py` (diversity > quantity)

## Roadmap (near-term)

- Add 3–5 additional wisdom Q/A templates (varied metaphors & structures)
- Validation split + basic metrics: Silence-to-Speech ratio, Holism score, B2Q ratio
- Stabilise training: gradient clipping; NaN-guard; label smoothing (optional)
- Memory diversity: multiple seeded paintings; decay/awakening heuristics per phase

## License

See top-level project LICENSE.
